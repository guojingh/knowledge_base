# Hello 算法

## 1. 初识算法

### 1.1 算法无处不在

当我们听到“算法”这个词时，很自然地会想到数学。然而实际上，许多算法并不涉及复杂数学，而是更多地依赖基本逻辑，这些逻辑我们在日常生活中也随处可见。

**例一：查字典**

1. 翻开字典约一半的页数，查看该页的首字母是什么，假设首字母为 m 。
2. 由于在拼音字母表中 r 位于 m 之后，所以排除字典前半部分，查找范围缩小到后半部分。
3. 不断重复步骤 `1.` 和步骤 `2.` ，直至找到拼音首字母为 r 的页码为止。

从数据结构角度，我们可以把字典视为一个已排序的“数组”；从算法角度，我们可以将上述查字典典一系列操作看作“二分法查找”。

**例二：整理扑克，我们在打牌时，每局都需要整理手中的扑克牌，使其从小到大排列。**

1. 将扑克牌划分为“有序”和“无序”两部分，并假设初始状态下最左 1 张扑克牌已经有序。

2. 在无序部分抽出一张扑克牌，插入至有序部分的正确位置；完成后最左 2 张扑克已经有序。

3. 不断循环步骤 `2.` ，每一轮将一张扑克牌从无序部分插入至有序部分，直至所有扑克牌都有序。

   ![image-20250319102457734](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20250319102457734.png)

上述整理扑克牌的方法本质上是“插入排序”算法，它在处理小型数据集时非常有效。许多编程语言的排序库函数中都有插入排序的身影。

**例三：货币找零**

假设我们在超市购买了 69 元的商品，给了收银员 100 元，则收银员需要找我们 31 元。

1. 可选项是比 31 元面值更小的货币，包括 1 元、5 元、10 元、20 元。

2. 从可选项中拿出最大的 20 元，剩余 31−20=11 元。

3. 从剩余可选项中拿出最大的 10 元，剩余 11−10=1 元。

4. 从剩余可选项中拿出最大的 1 元，剩余 1−1=0 元。

5. 完成找零，方案为 20+10+1=31 元。

   ![image-20250319102722636](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20250319102722636.png)

上述步骤中，我们每一步都采用当前看来最好的选择（尽可能用大面额的货币），最终得到了可行的找零方案。从数据结构和算法的角度来看，这种方法本质上是“贪心”算法。

### 1.2 算法是什么？

#### 1.2.1 算法定义

算法是在有限时间内解决特定问题的一组指令或操作步骤，它具有以下特性。

- 问题是明确的，包含清晰的输入和输出定义。
- 具有可行性，能够在有限步骤，时间和内存空间下完成。
- 各步骤都有确定的含义，在相同的输入和运行条件下，输出始终相同。

#### 1.2.2 数据结构定义

数据结构是组织和存储数据的方式，涵盖数据内容，数据之间的关系和数据操作方法，它具有以下设计目标。

- 空间占用尽量小，以节省计算机内存
- 数据操作尽可能快速，涵盖数据访问，添加，删除，更新等。
- 提供简洁的数据表示和逻辑信息，以便算法高效运行。

数据结构设计是一个充满权衡的过程。如果想在某方面取得提升，往往需要在另一方面作出妥协。下面举两个例子：

1. 链表相较于数组，在数据添加和删除操作上更加便捷，但牺牲了数据访问速度。
2. 图相较于链表，提供了更丰富的逻辑信息，但需要占用更大的空间。

#### 1.2.3 数据结构与算法的关系

![image-20250319103858529](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20250319103858529.png)

数据结构与算法高度相关，紧密结合，具体体现在以下三个方买呢。

1. 数据结构是算法的基石。数据结构为算法提供了结构化存储的数据，以及操作数据的方法。
2. 算法为数据结构注入生命力。数据结构本身仅存储数据信息，结合算法才能解决特定问题。
3. 算法通常可以基于不同的数据结构实习。但执行效率可能相差很大，选择合适的数据结构是关键的。

## 2. 复杂度分析

### 2.1 算法效率评估

在算法设计中，我们先后追求以下两个层面的目标。

1. 找到问题解决
2. 寻求最优解法：
   1. 时间效率
   2. 空间效率

简而言之，我们的目标是设计“既快又省”的数据结构与算法。

效率评估方法主要分为两种：实际测试，理论评估。

#### 2.1.1 实际测试

对比两个算法的效率，最直接的方法就是找一台计算机，运行这两个算法，并监控它们的运行时间和内存占用情况。这种方式能够反映真实情况，但是存在较大的局限性。

#### 2.1.2 理论估算

复杂度分析，它描述了随着输入数据大小的增加，算法执行所需时见和空间的增长资源。我们可以将其分为以下三个重点来理解。

1. “时间和空间资源”分别对应时间复杂度和空间复杂度
2. “随着输入数据大小的增加”意味着复杂度反映了算法运行效率与输入数据体量之间的关系。
3. “时间和空间的增长趋势”表示复杂度分析关注的不是运行时间或占用空间的具体值，而是时间或空间增长的“快慢”。

### 2.2 迭代与递归

算法中最常见的两种基本的程序控制结构：迭代与递归。

#### 2.2.1 迭代

迭代是一种重复执行某个任务的控制结构。在迭代中，程序会在满足一定的条件下重复执行某段代码，直到这个条件不再满足。

**1.for 循环**

`for` 循环是最常见的迭代形式之一，**适合在预先知道迭代次数时使用**。

以下函数基于for循环时间了求和 1+2+···+n，求和结果使用 res 记录。

```go
func forLoop(n int) int {
  res := 0
  for i := 1; i <= n; i++ {
    res += i
  }
  
  return res
}
```

该求和函数的流程图

![image-20250319110224447](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20250319110224447.png)

此求和函数的操作数量与输入数据大小n成正比，或者说成“线性关系”。实际上，时间复杂度描述的就是这个“线性关系”。

**2. while 循环**

与 `for` 循环类似，`while` 循环也是一种实现迭代的方法。在 `while` 循环中，程序每轮都会先检查条件，如果条件为真，则继续执行，否则就结束循环。

下面我们用 `while` 循环来实现求和 1+2+⋯+n ：

```go
func whileLoop(n int) int {
  res := 0
  // 初始化条件变量
  i := 1
  for i <= n {
    res += i
    i++
  }
  
  return res
}
```

while 循环比 for 循环的自由度更高。在 while 循环中，我们可以自由地设计条件变量的初始化和更新步骤。

例如，在下面代码中，条件变量 i 每轮进行两次更新，这种情况就不太方便使用 for 循环时间：

```go
func whileLoopII(n int) int {
  res := 0
  // 初始化条件变量
  i := 1
  // 循环求和
  for i <= n {
    res += i
    i++
    i *= 2
  }
  return res
}
```

总的来说，for 循环的代码更加紧凑， while 循环更加灵活，两者都可以实现迭代结构，选择使用哪一种应该根据特定特定问题的需求来决定。

**3. 嵌套循环**

我们可以在一个循环结构内嵌套另一个循环结构，下面以 for 循环为例

```go
func nestedForLoop(n int) string {
  res := ""
  // 循环 i = 1, 2, ..., n-1, n
  for i := 1; i <= n; i++{
    // 循环 j = 1, 2, ..., n-1, n
    for j := 1; j <= n; j++{
      res += fmt.Sprintf("(%d, %d),", i, j)
    }
  }
  
  return res
}
```

该嵌套循环的流程图

<img src="https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20250319112724650.png" alt="image-20250319112724650" style="zoom:50%;" />

在这种情况下，函数的操作数量与 n^2 成正比，或者说算法运行时间和输入数据大小 n 成“平方关系”。

#### 2.2.2 递归

递归是一种算法策略，通过函数调用自身来解决问题。它主要包含两个阶段。

1. **递**：程序不断深入地调用自身，通常传入更小或更简化的参数，知道达到“终止条件”。
2. **归**：触发“终止条件”后，程序从最深层的递归函数开始逐层返回，汇集每一层的结果。

而从实际的角度看，递归代码主要包含三个要素：

1. **终止条件：**用于决定什么时候由“递”转“归”
2. 递归调用：对应“递”，函数调用自身，通常输入更小或更简化的参数。
3. 返回结果：对应“归，将当前递归层级的返回结果返回至上一层。

下面代码，我们自需要调用函数 recur(n)，就可以完成 1+2+⋯+n 的计算：

```go
func recur(n int) int {
  	// 终止条件
  if n == 1 {
    return 1
  }
  // 递：递归调用
  res := recur(n - 1)
  // 归：返回结果
  return n + res
}
```

下图展示了该函数的递归过程：

![image-20250319140410613](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20250319140410613.png)

虽然从计算的角度看，迭代与递归可以得到相同的结果，但它们代表了两种完全不通的思考和解决问题的范式。

- **迭代：**“自下而上”递解决问题。从最基础的步骤开始，然后不断重复或累加这些步骤，知道任务完成。
- **递归：**“自上而下”地解决问题。将原问题分解为更小的子问题，这些子问题和原问题都具有相同的形式。接下来将子问题继续分解为更小的子问题，直到基本情况时停止（基本情况是已知的）。

以上述求和函数为例，设问题： f(n)=1+2+⋯+n 。

- 迭代：在循环过程中模式求和过程，从1遍历到n，每轮执行求和操作，即可求的 f(n)。
- 递归：将问题分解为子问题 f(n) = n + f(n-1)，不断（递归地）分解下去，直至基本情况 f(1) = 1 时终止。

**1.调用栈**

递归函数每次调用自身时，系统都会为新开启的函数分配空间，以存储局部变量，调用地址和其他信息等。这将导致两方面的结果。

- 函数的上下文数据都存储在称为“栈帧空间”的内存区域中，直至函数返回后才被释放。因此，递归通常比迭代更加耗费内存空间。

- 递归调用函数会产生额外的开销，因此递归通常比循环的时间效率更低。

  下图所示，在触发终止条件前，同时存在n个未返回的递归函数，递归深度为n。

  ![image-20250319142335216](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20250319142335216.png)

在实际中，编程语言运行的递归深度通常是有限的，过深的递归可能导致栈溢出的错误。

**2.尾递归**

有趣的是，如果函数在返回前的最后一步才进行递归调用，则该函数可以被编译器或解释器优化，使其空间效率上与迭代相当。这种情况被称为尾递归。

- 普通递归：当函数返回到上一层级的函数后，需要继续执行代码，因此系统需要保存上一层调用的上下文。
- 尾递归：递归调用是函数返回前的最后一个操作，这意味着函数返回到上一层级后，无需继续执行其他操作，因此系统无需保存上一层函数的上下文。

以计算 1+2+⋯+n 为例，我们可以将结果变量 `res` 设为函数参数，从而实现尾递归：

```go
// 尾递归
func tailRecur(n int, res int) int {
  //终止条件
  if n == 0 {
    return res 
  }
  // 尾递归调用
  return tailRecyr(n-1, res+n)
}
```

尾递归执行过程如下图所示，对比普通递归和尾递归，两者的求和操作的执行点是不同的。

- 普通递归：求和操作是在“归”的过程中执行的，每层返回后都要再执行一次求和操作。
- 尾递归：求和操作是在“递”的过程中执行的，“归”的过程只是需要层层返回。

![image-20250319145024138](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20250319145024138.png)

**3.递归树**

当处理与“分治”相关的算法问题时，递归往往比迭代的思路更加直观，代码更加易读。以“斐波那契数列为例”。

设斐波那契数列的第 n 个数字为 f(n) ，易得两个结论。

- 数列的前两个数字为 f(1)=0 和 f(2)=1 。
- 数列中的每个数字是前两个数字的和，即 f(n)=f(n−1)+f(n−2) 

按照递推关系进行递归调用，将前两个数字作为终止条件，便可写出递归代码。调用 fib(n) 即可得到斐波那契数列的第n个数字；

```go
// 斐波那契数列：递归
func fib(n int) int {
  // 终止条件 f(1) = 0, f(2) = 1
  if n == 1 || n == 2 {
    return n-1
  }
  // 递归调用 f(n) = f(n-1) + f(n-2)
  res := fib(n-1) + fib(n-2)
  return res
}

```

观察以上代码，我们在函数内递归调用了两个函数，这意味着从一个调用产生了两个调用分支。这样不断递归调用下去，最终产生了一棵层数为n的递归树。

![image-20250319150229070](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20250319150229070.png)

从本质上看，递归体现了“将问题分解为更小子问题”的思维范式，这种分治策略至关重要。

- 从算法角度看，搜索，排序，回溯，分治，动态规划等许多重要算法策略直接或间接地应用了这种视为方式。
- 从数据结构角度看，递归天然适合处理链表，树和图等相关问题，因为它们非常适合分治思想进行分析。

#### 2.2.3 两者对比

迭代和递归在实现，性能和适用性上有所不同

![image-20250319150716670](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20250319150716670.png)

那么，迭代和递归具有什么内在联系呢？以上述递归函数为例，求和操作在递归的“归”阶段进行。这意味着最初被调用的函数实际上是最后完成其求和操作的，**这种工作机制与栈的“先入后出”原则异曲同工**。

事实上，“调用栈”和“栈帧空间”这类递归术语已经暗示了递归与栈之间的密切关系。

1. **递**：当函数被调用时，系统会在“调用栈”上为该函数分配新的栈帧，用于存储函数的局部变量、参数、返回地址等数据。
2. **归**：当函数完成执行并返回时，对应的栈帧会被从“调用栈”上移除，恢复之前函数的执行环境。

### 2.3 时间复杂度

#### 2.3.1 统计时间增长趋势

时间复杂度分析统计等不是算法运行时间，而是算法运行时间随着数据量变大时的增长趋势。

“时间增长趋势”这个概念比较抽象，下面通过一个例子加以理解。假设输入数据大小为n，给定三个算法 A、B、C：

```go
// 算法 A 的时间复杂度：常数阶
func algorithm_A(n int) {
    fmt.Println(0)
}
// 算法 B 的时间复杂度：线性阶
func algorithm_B(n int) {
    for i := 0; i < n; i++ {
        fmt.Println(0)
    }
}
// 算法 C 的时间复杂度：常数阶
func algorithm_C(n int) {
    for i := 0; i < 1000000; i++ {
        fmt.Println(0)
    }
}
```

下面展示了以上三个算法函数的时间复杂度。

- 算法 `A` 只有 1 个打印操作，算法运行时间不随着 n 增大而增长。我们称此算法的时间复杂度为“常数阶”。

- 算法 `B` 中的打印操作需要循环 n 次，算法运行时间随着 n 增大呈线性增长。此算法的时间复杂度被称为“线性阶”。

- 算法 `C` 中的打印操作需要循环 1000000 次，虽然运行时间很长，但它与输入数据大小 n 无关。因此 `C` 的时间复杂度和 `A` 相同，仍为“常数阶”。

  ![image-20250319152441166](https://picpoahu.oss-cn-chengdu.aliyuncs.com/images/image-20250319152441166.png)

相较于直接统计算法的运行时间，时间复杂度分析有哪些特点呢？

- 时间复杂度能够有效评估算法效率。
- 时间复杂度的推算方法更简便。
- 时间复杂度也存在一定的局限性。





















